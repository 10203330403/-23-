{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\envs\\py361\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\python\\envs\\py361\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\python\\envs\\py361\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\python\\envs\\py361\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\python\\envs\\py361\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\python\\envs\\py361\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\python\\envs\\py361\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\python\\envs\\py361\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\python\\envs\\py361\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\python\\envs\\py361\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\python\\envs\\py361\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\python\\envs\\py361\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理训练集标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    " \n",
    "path = 'train.txt'\n",
    "# newline这里是去除行之间的空行\n",
    "\n",
    "df = pd.read_csv(path, sep=',', header=None,skiprows=1)\n",
    "df.columns = ['guid','tag']\n",
    "column_dict = {\"negative\": -1,\"neutral\": 0,\"positive\":1}\n",
    "    # new_df = df.replace({\"col1\": column_dict})\n",
    "df['tag'] = df['tag'].map(column_dict)\n",
    "df = df.sort_values(by=\"guid\")\n",
    "#df\n",
    "df.to_csv('data.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理图文数据"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载处理好的向量化的图文数据矩阵，并调整张量大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "a=np.load('picture_feature_train.npy',allow_pickle=True)\n",
    "#print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 2387), (-1.0, 1193), (0.0, 419)]\n"
     ]
    }
   ],
   "source": [
    "#导入写好的注意力机制\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "attention_keras = __import__(\"keras_attention_mechanism_model\")\n",
    "\n",
    "text_data = np.load('normalized_data.npy')\n",
    "#print(text_data.shape)\n",
    "text_data=text_data[:4000,:1500]\n",
    "#print(text_data.shape)\n",
    "text_data = text_data.reshape([-1, 30, 50])\n",
    "picture_filename = 'picture_feature_train.npy'\n",
    "picture_data = np.load(picture_filename)\n",
    "picture_data=picture_data.reshape(4000,16,32)\n",
    "\n",
    "with open('data.csv', 'r') as f:\n",
    "    df = pd.read_csv(f, delimiter=',', header=None)\n",
    "#print(df)\n",
    "labels=df[1][1:4000].values.astype(float)\n",
    "labels = np.array(labels)\n",
    "#print(labels)\n",
    "from collections import Counter\n",
    "d = Counter(labels)\n",
    "d_s = sorted(d.items(),key=lambda x:x[1],reverse=True)\n",
    "print(d_s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参数\n",
    "batch_size = 16\n",
    "epochs=50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Position_Embedding.call of <keras_attention_mechanism_model.Position_Embedding object at 0x00000189E64D5A90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Position_Embedding.call of <keras_attention_mechanism_model.Position_Embedding object at 0x00000189E64D5A90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Position_Embedding.call of <keras_attention_mechanism_model.Position_Embedding object at 0x00000189E64D5A90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Position_Embedding.call of <keras_attention_mechanism_model.Position_Embedding object at 0x00000189E64D5A90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Position_Embedding.call of <keras_attention_mechanism_model.Position_Embedding object at 0x00000189E651E0F0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Position_Embedding.call of <keras_attention_mechanism_model.Position_Embedding object at 0x00000189E651E0F0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Position_Embedding.call of <keras_attention_mechanism_model.Position_Embedding object at 0x00000189E651E0F0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Position_Embedding.call of <keras_attention_mechanism_model.Position_Embedding object at 0x00000189E651E0F0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From d:\\python\\envs\\py361\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Attention.call of <keras_attention_mechanism_model.Attention object at 0x00000189E15F7A58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Attention.call of <keras_attention_mechanism_model.Attention object at 0x00000189E15F7A58>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Attention.call of <keras_attention_mechanism_model.Attention object at 0x00000189E15F7A58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Attention.call of <keras_attention_mechanism_model.Attention object at 0x00000189E15F7A58>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Attention.call of <keras_attention_mechanism_model.Attention object at 0x00000189E161CDD8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Attention.call of <keras_attention_mechanism_model.Attention object at 0x00000189E161CDD8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Attention.call of <keras_attention_mechanism_model.Attention object at 0x00000189E161CDD8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Attention.call of <keras_attention_mechanism_model.Attention object at 0x00000189E161CDD8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Attention.call of <keras_attention_mechanism_model.Attention object at 0x00000189E161C5C0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Attention.call of <keras_attention_mechanism_model.Attention object at 0x00000189E161C5C0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Attention.call of <keras_attention_mechanism_model.Attention object at 0x00000189E161C5C0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Attention.call of <keras_attention_mechanism_model.Attention object at 0x00000189E161C5C0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "Train...\n",
      "Train on 3500 samples, validate on 499 samples\n",
      "Epoch 1/50\n",
      "3500/3500 - 3s - loss: 0.3890 - acc: 0.8777 - val_loss: 0.4173 - val_acc: 0.8597\n",
      "Epoch 2/50\n",
      "3500/3500 - 3s - loss: 0.3291 - acc: 0.9003 - val_loss: 0.4104 - val_acc: 0.8597\n",
      "Epoch 3/50\n",
      "3500/3500 - 3s - loss: 0.3319 - acc: 0.9003 - val_loss: 0.4074 - val_acc: 0.8597\n",
      "Epoch 4/50\n",
      "3500/3500 - 2s - loss: 0.3291 - acc: 0.9003 - val_loss: 0.4076 - val_acc: 0.8597\n",
      "Epoch 5/50\n",
      "3500/3500 - 2s - loss: 0.3284 - acc: 0.9003 - val_loss: 0.4242 - val_acc: 0.8597\n",
      "Epoch 6/50\n",
      "3500/3500 - 3s - loss: 0.3318 - acc: 0.9003 - val_loss: 0.4187 - val_acc: 0.8597\n",
      "Epoch 7/50\n",
      "3500/3500 - 3s - loss: 0.3271 - acc: 0.9003 - val_loss: 0.4086 - val_acc: 0.8597\n",
      "Epoch 8/50\n",
      "3500/3500 - 2s - loss: 0.3272 - acc: 0.9003 - val_loss: 0.4344 - val_acc: 0.8597\n",
      "Epoch 9/50\n",
      "3500/3500 - 2s - loss: 0.3246 - acc: 0.9003 - val_loss: 0.4095 - val_acc: 0.8597\n",
      "Epoch 10/50\n",
      "3500/3500 - 2s - loss: 0.3264 - acc: 0.9003 - val_loss: 0.4104 - val_acc: 0.8597\n",
      "Epoch 11/50\n",
      "3500/3500 - 3s - loss: 0.3236 - acc: 0.9003 - val_loss: 0.4137 - val_acc: 0.8597\n",
      "Epoch 12/50\n",
      "3500/3500 - 2s - loss: 0.3242 - acc: 0.9003 - val_loss: 0.4208 - val_acc: 0.8597\n",
      "Epoch 13/50\n",
      "3500/3500 - 3s - loss: 0.3217 - acc: 0.9003 - val_loss: 0.4125 - val_acc: 0.8597\n",
      "Epoch 14/50\n",
      "3500/3500 - 3s - loss: 0.3201 - acc: 0.9003 - val_loss: 0.4197 - val_acc: 0.8597\n",
      "Epoch 15/50\n",
      "3500/3500 - 2s - loss: 0.3209 - acc: 0.9003 - val_loss: 0.4066 - val_acc: 0.8597\n",
      "Epoch 16/50\n",
      "3500/3500 - 3s - loss: 0.3200 - acc: 0.9003 - val_loss: 0.4361 - val_acc: 0.8597\n",
      "Epoch 17/50\n",
      "3500/3500 - 2s - loss: 0.3158 - acc: 0.9003 - val_loss: 0.4175 - val_acc: 0.8597\n",
      "Epoch 18/50\n",
      "3500/3500 - 3s - loss: 0.3148 - acc: 0.9003 - val_loss: 0.4357 - val_acc: 0.8597\n",
      "Epoch 19/50\n",
      "3500/3500 - 3s - loss: 0.3128 - acc: 0.9003 - val_loss: 0.4122 - val_acc: 0.8597\n",
      "Epoch 20/50\n",
      "3500/3500 - 3s - loss: 0.3108 - acc: 0.9003 - val_loss: 0.4116 - val_acc: 0.8597\n",
      "Epoch 21/50\n",
      "3500/3500 - 2s - loss: 0.3087 - acc: 0.9003 - val_loss: 0.4328 - val_acc: 0.8597\n",
      "Epoch 22/50\n",
      "3500/3500 - 2s - loss: 0.3086 - acc: 0.9003 - val_loss: 0.4125 - val_acc: 0.8597\n",
      "Epoch 23/50\n",
      "3500/3500 - 2s - loss: 0.3022 - acc: 0.9003 - val_loss: 0.4198 - val_acc: 0.8597\n",
      "Epoch 24/50\n",
      "3500/3500 - 2s - loss: 0.3013 - acc: 0.9003 - val_loss: 0.4162 - val_acc: 0.8597\n",
      "Epoch 25/50\n",
      "3500/3500 - 2s - loss: 0.3046 - acc: 0.9003 - val_loss: 0.4442 - val_acc: 0.8597\n",
      "Epoch 26/50\n",
      "3500/3500 - 2s - loss: 0.2968 - acc: 0.9003 - val_loss: 0.4211 - val_acc: 0.8597\n",
      "Epoch 27/50\n",
      "3500/3500 - 2s - loss: 0.2932 - acc: 0.9006 - val_loss: 0.4216 - val_acc: 0.8597\n",
      "Epoch 28/50\n",
      "3500/3500 - 2s - loss: 0.2941 - acc: 0.9006 - val_loss: 0.4357 - val_acc: 0.8597\n",
      "Epoch 29/50\n",
      "3500/3500 - 2s - loss: 0.2912 - acc: 0.9003 - val_loss: 0.4416 - val_acc: 0.8597\n",
      "Epoch 30/50\n",
      "3500/3500 - 2s - loss: 0.2866 - acc: 0.9003 - val_loss: 0.4319 - val_acc: 0.8597\n",
      "Epoch 31/50\n",
      "3500/3500 - 2s - loss: 0.2841 - acc: 0.9011 - val_loss: 0.4367 - val_acc: 0.8597\n",
      "Epoch 32/50\n",
      "3500/3500 - 2s - loss: 0.2766 - acc: 0.9014 - val_loss: 0.4402 - val_acc: 0.8597\n",
      "Epoch 33/50\n",
      "3500/3500 - 2s - loss: 0.2769 - acc: 0.9009 - val_loss: 0.4504 - val_acc: 0.8597\n",
      "Epoch 34/50\n",
      "3500/3500 - 2s - loss: 0.2724 - acc: 0.9026 - val_loss: 0.4655 - val_acc: 0.8597\n",
      "Epoch 35/50\n",
      "3500/3500 - 2s - loss: 0.2740 - acc: 0.9034 - val_loss: 0.4455 - val_acc: 0.8597\n",
      "Epoch 36/50\n",
      "3500/3500 - 2s - loss: 0.2662 - acc: 0.9011 - val_loss: 0.4472 - val_acc: 0.8597\n",
      "Epoch 37/50\n",
      "3500/3500 - 2s - loss: 0.2677 - acc: 0.9029 - val_loss: 0.4635 - val_acc: 0.8597\n",
      "Epoch 38/50\n",
      "3500/3500 - 2s - loss: 0.2638 - acc: 0.9040 - val_loss: 0.4437 - val_acc: 0.8557\n",
      "Epoch 39/50\n",
      "3500/3500 - 2s - loss: 0.2610 - acc: 0.9069 - val_loss: 0.4870 - val_acc: 0.8597\n",
      "Epoch 40/50\n",
      "3500/3500 - 2s - loss: 0.2516 - acc: 0.9060 - val_loss: 0.4754 - val_acc: 0.8597\n",
      "Epoch 41/50\n",
      "3500/3500 - 2s - loss: 0.2559 - acc: 0.9086 - val_loss: 0.4730 - val_acc: 0.8577\n",
      "Epoch 42/50\n",
      "3500/3500 - 2s - loss: 0.2498 - acc: 0.9077 - val_loss: 0.4755 - val_acc: 0.8597\n",
      "Epoch 43/50\n",
      "3500/3500 - 2s - loss: 0.2491 - acc: 0.9083 - val_loss: 0.4775 - val_acc: 0.8617\n",
      "Epoch 44/50\n",
      "3500/3500 - 2s - loss: 0.2455 - acc: 0.9057 - val_loss: 0.5089 - val_acc: 0.8597\n",
      "Epoch 45/50\n",
      "3500/3500 - 2s - loss: 0.2392 - acc: 0.9123 - val_loss: 0.4960 - val_acc: 0.8597\n",
      "Epoch 46/50\n",
      "3500/3500 - 2s - loss: 0.2433 - acc: 0.9091 - val_loss: 0.4757 - val_acc: 0.8497\n",
      "Epoch 47/50\n",
      "3500/3500 - 2s - loss: 0.2335 - acc: 0.9154 - val_loss: 0.4707 - val_acc: 0.8457\n",
      "Epoch 48/50\n",
      "3500/3500 - 2s - loss: 0.2328 - acc: 0.9083 - val_loss: 0.5119 - val_acc: 0.8597\n",
      "Epoch 49/50\n",
      "3500/3500 - 2s - loss: 0.2231 - acc: 0.9129 - val_loss: 0.4957 - val_acc: 0.8557\n",
      "Epoch 50/50\n",
      "3500/3500 - 2s - loss: 0.2241 - acc: 0.9146 - val_loss: 0.5340 - val_acc: 0.8577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x189e1a78128>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "index = [i for i in range(len(labels))]\n",
    "index = np.random.permutation(index)\n",
    "text_data = text_data[index]\n",
    "picture_data = picture_data[index]\n",
    "labels = labels[index]\n",
    "labels = tf.keras.utils.to_categorical(labels)\n",
    "\n",
    "text_train_data = text_data[:3500]\n",
    "text_test_data = text_data[3500:]\n",
    "picture_train_data = picture_data[:3500]\n",
    "picture_test_data = picture_data[3500:]\n",
    "train_labels = labels[:3500]\n",
    "test_labels = labels[3500:]\n",
    "\n",
    "#train_labels[train_labels == 0] = 2\n",
    "#test_labels[test_labels == 0] = 2\n",
    "\n",
    "# 添加一个新的类别 0，用于表示第三个分类\n",
    "# 将原始标签中的 1 替换为 0\n",
    "#train_labels[train_labels == 1] = 0\n",
    "#test_labels[test_labels == 1] = 0\n",
    "\n",
    "# 将原始标签中的 2 替换为 1\n",
    "#train_labels[train_labels == 2] = 1\n",
    "#test_labels[test_labels == 2] = 1\n",
    "train_labels=np.argmax(train_labels,axis=1)\n",
    "test_labels=np.argmax(test_labels,axis=1)\n",
    "\n",
    "#转换为三种类别的情绪向量标签以计算损失函数\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=3)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=3)\n",
    "\n",
    "\n",
    "#根据图文张量大小设置模型输入输出函数\n",
    "S_inputs1 = tf.keras.Input(shape=(30,50), dtype='float32')\n",
    "S_inputs2 = tf.keras.Input(shape=(16,32), dtype='float32')\n",
    "\n",
    "#位置信息编码\n",
    "text_embeddings = attention_keras.Position_Embedding()(S_inputs1)\n",
    "picture_embeddings = attention_keras.Position_Embedding()(S_inputs2)\n",
    "\n",
    "#embedding传入图文数据\n",
    "#多头注意力机制\n",
    "O_seq_1 = attention_keras.Attention(8, 16)([picture_embeddings, text_embeddings, text_embeddings])\n",
    "O_seq_1 = tf.keras.layers.Activation('relu')(O_seq_1)\n",
    "\n",
    "O_seq_2 = attention_keras.Attention(8, 16)([text_embeddings, picture_embeddings, picture_embeddings])\n",
    "O_seq_2 = tf.keras.layers.Activation('relu')(O_seq_2)\n",
    "\n",
    "O_seq_3 = attention_keras.Attention(8, 16)([picture_embeddings, picture_embeddings, picture_embeddings])\n",
    "O_seq_3 = tf.keras.layers.Activation('relu')(O_seq_3)\n",
    "#拼接三种张量\n",
    "O_seq = tf.concat((O_seq_1, O_seq_2, O_seq_3), axis=1)\n",
    "#O_seq = tf.concat((O_seq_1), axis=1)\n",
    "#平均池化\n",
    "O_seq = tf.keras.layers.GlobalAveragePooling1D()(O_seq)\n",
    "#正则化防止过拟合\n",
    "O_seq = tf.keras.layers.Dropout(0.3)(O_seq)\n",
    "#增加全连接层\n",
    "outputs = tf.keras.layers.Dense(3, activation='softmax')(O_seq)\n",
    "#print(outputs)\n",
    "#根据输入输出的张量大小实体化一个网络模型\n",
    "model = tf.keras.models.Model(inputs=[S_inputs1, S_inputs2], outputs=outputs)\n",
    "\n",
    "#优化器\n",
    "adam = tf.keras.optimizers.Adam(lr=5e-4)\n",
    "#adam = tf.keras.optimizers.Adam(lr=2e-4)#85\n",
    "#配置模型\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "#开始训练\n",
    "print('Train...')\n",
    "#filepath=\"model_save/a.h5\"\n",
    "#checkpoint=tf.keras.callbacks.ModelCheckpoint(filepath=filepath,monitor='val_accuracy',verbose=1,save_best_only=True,)\n",
    "#checkpoint=tf.keras.callbacks.ModelCheckpoint(filepath=filepath,verbose=1,save_best_only=True,)\n",
    "#model.fit(x={'input_1': text_train_data, 'input_2': picture_train_data}, y=train_labels, batch_size=batch_size, epochs=50, verbose=2,\n",
    "#         validation_data=([text_test_data, picture_test_data], test_labels))\n",
    "model.fit(x={'input_1': text_train_data, 'input_2': picture_train_data}, y=train_labels, batch_size=batch_size, epochs=epochs, verbose=2,\n",
    "         validation_data=([text_test_data, picture_test_data], test_labels))\n",
    "# Fit the model\n",
    "#model.fit(X_train, y_train, validation_data=(X_test, y_test),epochs=30, batch_size=200,callbacks=[checkpoint],verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 加载要预测的数据\n",
    "text_filename = 'normalized_data.npy'\n",
    "text_data = np.load(text_filename)\n",
    "text_data=text_data[4000:4511,:1500]\n",
    "text_data = text_data.reshape([-1, 30, 50])\n",
    "visual_filename = 'picture_feature_test.npy'\n",
    "visual_data = np.load(visual_filename)\n",
    "visual_data=visual_data.reshape(511,16,32)\n",
    "\n",
    "# 进行预测\n",
    "predictions = model.predict({'input_1': text_data, 'input_2': visual_data})\n",
    "predictions=np.argmax(predictions,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     guid       tag\n",
      "0       8  positive\n",
      "1    1576  positive\n",
      "2    2320  positive\n",
      "3    4912  positive\n",
      "4    3821  positive\n",
      "..    ...       ...\n",
      "506  1048   neutral\n",
      "507  1059  positive\n",
      "508  1485  positive\n",
      "509  3195   neutral\n",
      "510  2029  positive\n",
      "\n",
      "[511 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "paths = 'test_without_label.txt'\n",
    "df1 = pd.read_csv(paths, sep=',', header=None,skiprows=1)\n",
    "df1=df1.drop(columns=1)\n",
    "df1['tag'] = predictions\n",
    "df1.columns = ['guid','tag']\n",
    "column_dict = {-1: \"negative\",0: \"neutral\",1:\"positive\"}\n",
    "df1['tag'] = df1['tag'].map(column_dict)\n",
    "print(df1)\n",
    "df1.to_csv('submit_result.csv',sep=',',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py361",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
